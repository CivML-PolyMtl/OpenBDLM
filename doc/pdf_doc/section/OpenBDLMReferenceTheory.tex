\section{Reference Theory}
This section presents a summary of the theory behind Bayesian Dynamic Linear Models. For in-depth details, the reader should consult the following references:\\[4pt]

\noindent \emph{A Kernel-based Method for Modeling Non-Harmonic Periodic Phenomena in Bayesian Dynamic Linear Models}\\{\small
            Nguyen, L.H., Gaudot, I., Shervin Khazaeli and Goulet, J.-A.\\
            Frontiers in Built Environment. Vol. 5, pp8, 2019\\}
      [\href{https://www.polymtl.ca/cgm/jagoulet/Site/Papers/Nguyen_et_al_KR_BDLM_2019.pdf}{PDF}] [\href{https://www.polymtl.ca/cgm/jagoulet/Site/Papers/2019_Nguyen_BDLM_KR.enw}{EndNote}]  [\href{https://www.polymtl.ca/cgm/jagoulet/Site/Papers/2019_Nguyen_BDLM_KR.bib}{BibTex}] [\href{https://doi.org/10.3389/fbuil.2019.00008}{DOI link}] \cite{Nguyen2019KRBDLM}\\[4pt]

\noindent \emph{Uncertainty quantification for model parameters and hidden state variables in bayesian dynamic linear models}\\{\small
            Nguyen, L.H., Gaudot, I., and Goulet, J.-A.\\
            Structural Control and Health Monitoring. Vol. 26, Issue 3, pp.e2136, 2019\\}
      [\href{https://www.polymtl.ca/cgm/jagoulet/Site/Papers/Nguyen_Gaudot_Goulet_MCMC_BDLM_2018.pdf}{PDF}] [\href{https://www.polymtl.ca/cgm/jagoulet/Site/Papers/2019_Nguyen_BDLM_UC.xml}{EndNote}]  [\href{https://www.polymtl.ca/cgm/jagoulet/Site/Papers/2019_Nguyen_BDLM_UC.bib}{BibTex}] [\href{https://doi.org/10.1002/stc.2309}{DOI link}] \cite{Nguyen2018UncertaintyBDLM}\\[4pt]
      
      \noindent \emph{Anomaly Detection with the Switching Kalman Filter for Structural Health Monitoring}\\{\small
            Nguyen, L.H. and Goulet, J.-A.\\
            Structural Control and Health Monitoring. Vol. 24, Issue 4, pp.e2136, 2018\\}
      [\href{https://www.polymtl.ca/cgm/jagoulet/Site/Papers/2017_Nguyen_and_Goulet_AD-SKF.pdf}{PDF}] [\href{https://www.polymtl.ca/cgm/jagoulet/Site/Papers/Nguyen_SKF_2018.xml}{Endnote}]  [\href{https://www.polymtl.ca/cgm/jagoulet/Site/Papers/Nguyen_SKF_2018.ris}{BibTeX}] [\href{https://doi.org/10.1002/stc.2136}{DOI link}] \cite{Nguyen2018}\\[4pt]

\noindent \emph{Structural health monitoring with dependence on non-harmonic periodic hidden covariates}\\{\small
            Nguyen, L.H. and Goulet, J.-A.\\
            Engineering Structures, 166:187 √ê 194., 2018\\}
      [\href{https://www.polymtl.ca/cgm/jagoulet/Site/Papers/2018_Nguyen_et_Goulet_SHMHNHC.pdf}{PDF}] [\href{https://www.polymtl.ca/cgm/jagoulet/Site/Papers/2018_Nguyen_et_Goulet_HNHC.xml}{Endnote}]  [\href{https://www.polymtl.ca/cgm/jagoulet/Site/Papers/2018_Nguyen_et_Goulet_HNHC.bib}{BibTeX}] [\href{https://doi.org/10.1016/j.engstruct.2018.03.080}{DOI link}] \cite{Nguyen2018187}\\[4pt]

\noindent \emph{Empirical validation of Bayesian Dynamic Linear Models in the context of Structural Health Monitoring}\\{\small
            Goulet, J.-A. and Koo, K.\\
            Journal of Bridge Engineering. Vol. 23, Issue 2, pp. 05017017, 2018\\}
      [\href{https://www.polymtl.ca/cgm/jagoulet/Site/Papers/Goulet_BDLM_tamar_2017.pdf}{PDF}] [\href{https://www.polymtl.ca/cgm/jagoulet/Site/Papers/Goulet_BDLM_2018.xml}{Endnote}]  [\href{https://www.polymtl.ca/cgm/jagoulet/Site/Papers/Goulet_BDLM_2018.ris}{BibTeX}] [\href{https://doi.org/10.1061/\%28ASCE\%29BE.1943-5592.0001190}{DOI link}] \cite{Goulet2017BDLMEmprical}\\[4pt]

\noindent \emph{Bayesian dynamic linear models for structural health monitoring}\\{\small
            Goulet, J.-A.\\
            Structural Control and Health Monitoring. Vol. 24, Issue 12, pp.e2025, 2017\\}
      [\href{https://www.polymtl.ca/cgm/jagoulet/Site/Papers/Goulet_BDLM_SHM_2017_preprint.pdf}{PDF}] [\href{https://www.polymtl.ca/cgm/jagoulet/Site/Papers/Goulet_BDLM_2017.xml}{Endnote}]  [\href{https://www.polymtl.ca/cgm/jagoulet/Site/Papers/Goulet_BDLM_2017.ris}{BibTeX}] [\href{https://doi.org/10.1002/stc.2035}{DOI link}] \cite{STC:STC2035} \\

 
\subsection{Linear gaussian state-space model}
\label{SS:LGSSM}
OpenBDLM builds on Bayesian dynamic linear models (BDLMs).
Bayesian dynamic linear models \cite{west1999bayesian} are a class of linear gaussian state-space models which can be described from the transition and the observation equations.
The transition equation describes the dynamics of the system, and is formulated as
\begin{equation}
  \mathbf{x}_{t}=\mathbf{A}_{t}\mathbf{x}_{t-1}+\mathbf{w}_{t},\quad\left\{
  \begin{array}{l}
\mathbf{x}_{t}\sim \mathcal{N}(\bm{\mu}_{t},\bm{\Sigma}_{t})\\[4pt]
\mathbf{w}_{t}\sim \mathcal{N}(\mathbf{0},
\mathbf{Q}_{t}),
\end{array}\right.
\label{EQ:SSM_Transition}
\end{equation}
where, for each each time $t=1, \dots ,\mathtt{T}$, the variables $\mathbf{x}_{t}$ follow a Gaussian distribution with mean $\bm{\mu}_{t}$ and covariance matrix $\bm{\Sigma}_{t}$, $\mathbf{A}_{t}$ is the transition matrix, and $\mathbf{w}_{t}$ represents Gaussian model errors with zero mean and covariance matrix $\mathbf{Q}_{t}$.
The variables $\mathbf{x}_{t}$ are referred to as hidden states because they are not directly observed.
The relationship between the observations $\mathbf{y}_{t}$ and the hidden states $\mathbf{x}_{t}$ is given by the observation equation, such as
\begin{equation}
\mathbf{y}_{t}=\mathbf{C}_{t}\mathbf{x}_{t}+\mathbf{v}_{t},\quad\left\{\begin{array}{l}
\mathbf{v}_{t}\sim \mathcal{N}(\mathbf{0},\mathbf{R}_{t}),
\end{array}\right.
\label{EQ:SSM_Observation}
\end{equation}
where $\mathbf{C}_{t}$ is the observation matrix, and $\mathbf{v}_{t}$ is the Gaussian measurement error with zero mean and covariance matrix $\mathbf{R}_{t}$.
BDLMs are capable of analyzing multiple time series simultaneously.
In case of dependencies between the time series, regression coefficients are added in $\mathbf{C}_{t}$ (see Section~\ref{S:Dependencies} and \cite{STC:STC2035}).
One particularity of BDLMs is their capacity to update the current estimated state with the current observations, thus allowing to perform online state estimation for non-stationary time series.

\subsection{Kalman filter \& UD filters}
\label{SS:KFUD}
The analytical solutions for the prediction, observation and update step are available through either the Kalman filter (KF) or the UD filter, which can be expressed in its short form as
\begin{equation}
    \begin{split}
      (\bm{\mu}_{t|t},\bm{\Sigma}_{t|t}, \mathcal{L}_{t}) = \text{Filter}(\bm{\mu}_{t-1|t-1},\bm{\Sigma}_{t-1|t-1},\mathbf{y}_{t}, \mathbf{A}_{t},  \mathbf{Q}_{t},   \mathbf{C}_{t},  \mathbf{R}_{t}),
      \end{split}
\label{EQ:KF}
\end{equation}
where $\mathcal{L}_{t}$ is the marginal likelihood describing the probability of observing observations $\mathbf{y}_{t}$ at time $t$ given all the observations up to time $t-1$ \cite{sarkka2013bayesian}. 
Note that the UD and Kalman filter are two different methods for calculating the same results. On one hand, the Kalman filter is faster and computationally simpler to implement, and on the other hand, the UD filter is more robust toward numerical instabilities.   


The standard Kalman filter expressed in Eq.~\ref{EQ:KF} can process stationary, trend stationary, and acceleration stationary time series, but it is not capable of handling non-stationary time series, which is needed when it comes to anomaly detection (see \S\ref{S:ExampleDispAnomaly}).
The generalization of the Kalman Filter for non-stationary time series is found in the Switching Kalman filter (SKF) equations.

\subsection{Switching Kalman filter}
\label{SS:THSKF}
We may be interested in anomaly detection, that is, modelling and detecting the changes of regimes in the dynamics of the baseline response of the time series.
One way to model changing dynamics is to run in parallel a collection of ${\mathtt{S}}$ linear models, each having their own system dynamics $\mathbf{A}_{t}$ and $ \mathbf{Q}_{t}$.
%In the Switching Kalman filter (SKF) approach \citep{Murphy1998}, a collection of $S$ linear models are run in parallel.
%Each linear model has its own system dynamics (i.e their own $\mathbf{A}_{t}$ and $ \mathbf{Q}_{t}$ matrices).
In such approach, a discrete markovian switching variable $s_{t}= 1, ..,j,.. ,\mathtt{S}$ with a transition probabilities matrix $\mathbf{Z}_{t}$ and probabilities $\bm{\pi}_{t}$ is introduced to indicate which dynamics is used at time $t$.
The problem of incorporating switching dynamics into the model is that the state vector grows in a way that the dimension of the state vector at time $t$ is $\mathtt{S}^{t}$.
Therefore, the estimation quickly becomes intractable.
One solution is to merge at each time $t$ the states sharing the same dynamics using gaussian mixture.
This technique, known as the Switching Kalman filter, allows to keep the dimension of the state vector equal to $\mathtt{S}$ at each time $t$ \cite{murphy2012machine}.
The SKF algorithm can be divided into two successive steps, (i) the ``Filter'' and, (ii) the ``Collapse'' step.
Following the notation used in Eq.~\ref{EQ:KF} the first step can be expressed in its short form as
\begin{equation}
  \begin{split}
  (\bm{\mu}_{t|t}^{i(j)},\bm{\Sigma}_{t|t}^{i(j)}, \mathcal{L}_{t}^{i(j)}) = \text{Filter}(\bm{\mu}_{t-1|t-1}^{i},\bm{\Sigma}_{t-1|t-1}^{i}, \mathbf{y}_{t}, \mathbf{A}_{t}^{j},  \mathbf{Q}_{t}^{i(j)},   \mathbf{C}^{j}_{t},  \mathbf{R}^{j}_{t}),
    \end{split}
\label{EQ:SKF1}
\end{equation}
where the superscripts $i(j)$ indicates that the current state at time $t$ is $s_{t}=j$ given the state at time $t-1$ is $s_{t-1}=i$, and
$ \mathcal{L}_{t}^{i(j)}$  the marginal likelihood that describes the probability of observing observations $\mathbf{y}_{t}$ at time $t$ given all the observations up to time $t-1$, and given the state at time $t_1$ was $s_{t-1} = i$ and that it switches to $s_{t} = j$ at time $t$.
The state probability $\mathbf{\pi}_{t|t}^{j}$ at each time $t$ is computed from the previous state probabilities $\bm{\pi}_{t-1|t-1}$, the likelihood $\mathcal{L}_{t}^{i(j)}$, and the transition probability $Z_{t}^{i(j)}$, such as
\begin{equation}
\pi_{t|t}^{j} = \sum_{i=1}^{\mathtt{S}} \frac{\mathcal{L}_{t}^{i(j)} \pi_{t-1|t-1}^{i} Z^{i(j)}_{t} }{c},
\label{EQ:StateProbability}
\end{equation}
where $c$ is a normalization constant ensuring that $ \sum_{j=1}^{\mathtt{S}} \pi_{t|t}^{j} = 1 $.
Moreover, the state switching probability is defined as
\begin{equation}
W_{t-1|t}^{i(j)} = \frac{\mathcal{L}_{t}^{i(j)} \pi_{t-1|t-1}^{i} Z^{i(j)}_{t} }{c\pi_{t|t}^{j}}.
\label{EQ:StateSwitchingProbability}
\end{equation}
$W_{t|t-1}^{i(j)}$ are required to perform the ``Collapse'' step, which can be expressed in its short form as
\begin{equation}
  \begin{split}
  (\bm{\mu}_{t|t}^{j},\bm{\Sigma}_{t|t}^{j}) = \text{Collapse}(\bm{\mu}_{t|t}^{i(j)},\bm{\Sigma}_{t|t}^{i(j)}, W_{t-1|t}^{i(j)} ),
    \end{split}
\label{EQ:SKF2}
\end{equation}
where state switching probabilities $W_{t|t-1}^{i(j)}$ are used as weighting factors for the gaussian mixture.
From Eq.~\ref{EQ:SKF2}, the SKF algorithm provides a set a $\mathtt{S}$ state vectors at each time $t$.
However, for the ease of interpretation, it is generally more convenient to have a single state vector at each time $t$.
Therefore, we hereafter introduce the ``Merge'' step.
Similarly to the ``Collapse'' step of the SKF algorithm, the ``Merge'' step uses the gaussian mixture technique, and it can be expressed in its short form as
\begin{equation}
  \begin{split}
  (\bm{\mu}_{t|t},\bm{\Sigma}_{t|t}) = \text{Merge}(\bm{\mu}_{t|t}^{j},\bm{\Sigma}_{t|t}^{j},  \pi_{t|t}^{j} ),
    \end{split}
\label{EQ:SKFCollapse}
\end{equation}
where the state probabilities $\pi_{t|t}^{j}$ is used as weighting factors for the gaussian mixture \cite{Nguyen2018}.

\subsection{Model parameter estimation}
\label{SS:THModelParameterEstimation}
The model matrices $\left\{\mathbf{A}_{t}, \mathbf{Q}_{t}, \mathbf{C}_{t}, \mathbf{R}_{t}\right\}$ contain a vector of unknown model parameters $\bm{\theta}$ to be learned from data $\mathbf{y}_{1:\mathtt{Tr}}$.
This section presents different methods for optimizing the vector of model parameter in OpenBDLM.
\subsubsection{Likelihood}
The likelihood is the joint prior probability density of observations, i.e. the plausibility of the available observations $\mathbf{y}_{1:\mathtt{Tr}}$ given a vector of model parameters $\bm\theta$.  
Assuming that the observations are conditionally independent from each other, the joint likelihood function is defined as the product of the marginal likelihoods such that
\begin{equation}
p(\mathbf{y}_{1:\mathtt{Tr}}|\bm\theta)  = \displaystyle\prod_{t=1}^{\mathtt{Tr}} p(\mathbf{y}_{t}|\mathbf{y}_{1:t-1},\bm \theta) = \displaystyle\prod_{t=1}^{\mathtt{Tr}}\prod_{j=1}^{\mathtt{S}} \prod_{i=1}^{\mathtt{S}} \mathcal{L}_{t}^{i(j)}\cdot Z_{t}^{i(j)}\cdot\pi_{t-1|t-1}^{i} ,
\label{EQ:LP}
\end{equation}
where $\mathcal{L}_{t}^{i(j)}$ is defined in Equation \ref{EQ:SKF1}, $\mathtt{S}$ is the number of model class (see \ref{SS:THSKF}), $Z_{t}^{i(j)}$ is the transition probability, and $\pi_{t-1|t-1}^{i}$ the previous state probability. In order to avoid the underflow and overflow issue, the joint likelihood function presented in Equation \ref{EQ:LP} is transformed into the nature logarithm space, so that
\begin{equation}
\ln p(\mathbf{y}_{1:\mathtt{Tr}}|\bm\theta)  =  \displaystyle\sum_{t=1}^{\mathtt{Tr}} \ln \left[ \sum_{j=1}^{\mathtt{S}} \sum_{i=1}^{\mathtt{S}} \mathcal{L}_{t}^{i(j)}\cdot Z_{t}^{i(j)}\cdot\pi_{t-1|t-1}^{i} \right],
\label{EQ:LP}
\end{equation}
where $\ln p(\mathbf{y}_{1:\mathtt{Tr}}|\bm\theta) $ is the log-likelihood function. Note that when a single regime is employed, Equation \ref{EQ:LP} simplifies to
\begin{equation}
\ln p(\mathbf{y}_{1:\mathtt{Tr}}|\bm\theta)  =  \displaystyle\sum_{t=1}^{\mathtt{Tr}} \ln  \mathcal{L}_{t},
\end{equation}


\subsubsection{Maximum Likelihood Estimation (MLE)}

The \emph{Maximum Likelihood Estimation} (MLE) \cite{gelman2014bayesian} consists in finding a single vector that maximizes the log-likelihood function presented in Equation \ref{EQ:LP},
\begin{equation*}
\bm\theta^{*} = \underset{\bm\theta}{\text{arg}\max}\left[\ln  p(\mathbf{y}_{1:\mathtt{Tr}}|\bm\theta) \right] \text{,}
\end{equation*}
where $\bm\theta^{*}$ is the optimal vector of model parameters. The optimization task can be done using the gradient-based optimization algorithm such as \emph{gradient ascent} and \emph{stochastic gradient ascent}  \cite{Goodfellow-et-al-2016}.

\subsubsection{Gradient-based optimization}
In OpenBDLM, the gradient-based optimization method available are  the \emph{batch gradient ascent algorithm} and \emph{stochastic gradient ascent algorithm}.  For the purpose of simplicity, the log-likelihood function presented in Equation \ref{EQ:LP} is denoted as $\mathcal{T}(\bm\theta, \mathbf{y}_{1:\mathtt{Tr}})$ that is a function of a vector of model parameter $\bm\theta$ and a training dataset $\mathbf{y}_{1:\mathtt{Tr}}$.

\paragraph{Batch Gradient Ascent  (BGA)}
The BGA algorithm is used to maximize the log-likelihood function by updating the vector of model parameters with a small step $\Delta_{\bm\theta}$ in the direction of gradient for the entire training data $\mathbf{y}_{1:\mathtt{Tr}}$,
\begin{equation}
\bm\theta^{n} = \bm\theta^{n-1} + \underbrace{\eta\cdot \nabla\mathcal{T}(\bm\theta^{n-1}, \mathbf{y}_{1:\mathtt{Tr}})}_{\Delta_{\bm\theta}},
\end{equation}
where $n$ corresponds the optimization loop, $\eta$ is the learning rate to be defined by the user, and $\nabla$ is the operator for evaluating the first derivative of the log-likelihood function. The BGA algorithm only optimizes one model parameters at a time. The parameter-wise Newton-Raphson (NR) algorithm \cite{gelman2014bayesian} that uses both the first and second derivatives for performing the model parameter updates is implemented for the BGA. For the BGA algorithm a converged vector $\bf{c}$ is defined following
\begin{equation}
\mathbf{c}(i) = \left\{\begin{array}{lll}
1&\text{if} ~\mathcal{T}(\bm\theta^{n}, \mathbf{y}_{1:\mathtt{Tr}})> \mathcal{T}(\bm\theta^{n-1}, \mathbf{y}_{1:\mathtt{Tr}})~\text{and}~\left|\tfrac{\mathcal{T}(\bm\theta^{n}, \mathbf{y}_{1:\mathtt{Tr}})- \mathcal{T}(\bm\theta^{n-1}, \mathbf{y}_{1:\mathtt{Tr}})}{\mathcal{T}(\bm\theta^{n-1}, \mathbf{y}_{1:\mathtt{Tr}})}\right|<\tau\\
0 &\text{otherwise},
\end{array}\right.
\end{equation}
where $\tau$ is a termination tolerance and $i$ corresponds to $i^{th}$ model parameter of $\bm\theta$. The convergence criteria is reached when all elements of $\bf{c}$ are equal to $1$, or if the number of iteration reaches the maximal number of specified by the user. 



\paragraph{Stochastic Gradient Ascent (SGA)}  In order to improve the computational efficiency when using large datasets, OpenBDLM employs Stochastic Gradient Ascent SGA. The SGA optimization algorithms available in OpenBDLM are : \emph{momentum} and  \emph{adaptive moment estimation} \cite{Goodfellow-et-al-2016}. Instead of using a full batch dataset, the SGA algorithms employ mini-batches of the training data to update $\bm\theta$. The update equation is given by
\begin{equation}
\bm\theta^{n} = \bm\theta^{n-1} + \eta\cdot \nabla\mathcal{T}(\bm\theta^{n-1}, \mathbf{y}_{t:t+l_{\mathtt{MB}})},
\end{equation}
where $l_{\mathtt{MB}}$ is the length of the mini-batch. The SGA can update the model parameters either once at time, or all at once.  An epoch  is completed when the vector of  model parameters is updated $\mathtt{round}(\mathtt{Tr}/ l_{\mathtt{MB}})$ times, where $\mathtt{round}$ provides the closest integer. In order to avoid biasing the SGA algorithm, the mini-batch is randomly selected at every update. The SGA stops when the number of epochs reach the limit specified by the user.

\paragraph{Approximation of the derivatives}

In BDLMs, the derivatives of the log-likelihood function are  approximated numerically using the central differentiation scheme, so that
\begin{equation}
\begin{array}{lcl}
 \nabla \mathcal{T}(\bm\theta(i),\mathbf{y}_{1:\mathtt{Tr}}) & = &\dfrac{\mathcal{T}(\bm\theta(i) + \delta_{\theta}, \mathbf{y}_{1:\mathtt{Tr}}) - \mathcal{T}(\bm\theta(i) - \delta_{\theta}, \mathbf{y}_{1:\mathtt{Tr}})}{2\delta_{\theta}}\\[12pt]
 
 \nabla \nabla \mathcal{T}(\bm\theta(i),\mathbf{y}_{1:\mathtt{Tr}}) & = & \dfrac{\mathcal{T}(\bm\theta(i) + \delta_{\theta}, \mathbf{y}_{1:\mathtt{Tr}}) - \mathcal{T}(\bm\theta(i), \mathbf{y}_{1:\mathtt{Tr}}) + \mathcal{T}(\bm\theta(i) - \delta_{\theta}, \mathbf{y}_{1:\mathtt{Tr}})}{\delta_{\theta}^{2}},
\label{EQ:numericaldiff}
\end{array}
\end{equation}
where $\delta_{\theta}$ is a small perturbation to the value of the $i^{\text{th}}$ model parameter.
\subsubsection{Laplace Approximation}

The MLE approach are point estimation methods which do not take into account the uncertainty in the parameter estimates $\bm\theta^{*}$. 
The model parameter uncertainties can be quantified using the Laplace approximation \cite{gelman2014bayesian} such that
$$p(\bm\theta|\mathbf{y}_{1:\mathtt{Tr}})  \approx  \mathcal{N}\left(\bm\theta;\bm\theta^{*},-\mathbf{H}(\bm\theta^{*})^{-1}\right),
\label{EQ: LaA}
$$
where $\mathbf{H}(\bm\theta^{*})$ is the second derivative of the negative log-likelihood function evaluated at the optimal vector of model parameters $\bm\theta^{*}$. 

\subsubsection{Model parameter space transformation}
\label{SS:THSpaceTransformation}

In OpenBDLM, some model parameters  are defined in a bounded interval. During the learning procedure, it may happen that new model parameters $\bm\theta_{\text{new}}$ are proposed outside their valid interval.
Those parameters must be rejected, which hinders the computational efficiency of the optimization algorithm.
The solution to tackle this problem proposed for OpenBDLM is to transform these bounded model parameters into an unbounded space, where the parameters lie in the interval $[ -\infty, +\infty ]$. The transformation is done using a function $g(.)$ so that, 
\begin{equation}
\theta^{\text{tr}} = g(\theta) \text{, }\quad \theta^{\text{tr}} \in [-\infty, +\infty ] \text{.}
\end{equation}
The choice of the function $g(.)$ depends on the bound of $\theta$. 
Three cases generally occur:
\begin{itemize}
\item $ \theta \in [-\infty, +\infty ]$ , $g(\theta) = 1$, so that $\theta^{\text{tr}} = \theta$ and $\theta = \theta^{\text{tr}} $
\item $ \theta \in [0, +\infty ]$, $g(\theta) = \ln(\theta)$, so that $\theta^{\text{tr}} = \ln(\theta) $ and $\theta = e^{\theta^{\text{tr}}} $
\item $ \theta \in [\text{a}, \text{b}]$, $g(\theta) = \text{sigmoid}(\theta)$, so that $\theta^{\text{tr}} = -\ln \left( \frac{b-a}{\theta-a} - 1\right) $, and $\theta = \left( \frac{b-a}{1+e^{-\theta^{\text{tr}}}} + a \right).$
\end{itemize}
%For instance, the standard deviation model parameters are real numbers that lie in the $[0, +\infty]$ interval and the logarithm transformation is used.
%Moreover, the autoregression coefficient model parameters are real numbers that lie in the $[0, 1]$ interval, and the sigmoid transformation is used.

%\subsection{Model parameter estimation}
%\label{SS:THModelParameterEstimation}
%The matrices $\mathbf{A}_{t}$,  $\mathbf{Q}_{t}$,   $\mathbf{C}_{t}$ and  $\mathbf{R}_{t}$ depend on a set of model parameters $\bm{\theta}$.
%In most cases, $\bm{\theta}$ are unknown, and they can be learned from a training dataset $\mathbf{y}_{1:\mathtt{Tr}}$.
%The procedure of learning the model parameters is hereafter referred to as model parameters estimation.
%\subsubsection{Maximum log A Posteriori (MAP)}
%
%The log a posteriori probability density function (PDF) is defined as
%\begin{equation}
%%\begin{array}{rcl}
%\ln p(\bm\theta|\mathbf{y}_{1:\mathtt{Tr}}) \, \propto \, \ln p(\mathbf{y}_{1:\mathtt{Tr}}|\bm\theta) + \ln p(\bm\theta),
%%\end{array}
%\label{EQ:BT}
%\end{equation} 
%where $p(\mathbf{y}_{1:\mathtt{Tr}}|\bm\theta)$ is the likelihood,  $p(\bm\theta)$ is the prior PDF.
%The likelihood PDF is the joint prior probability density of observations, that is, plausibility of the available observations $\mathbf{y}_{1:\mathtt{Tr}}$ given the parameter vector $\bm\theta$.  
%Assuming that the observations errors are independent from each other, the joint log-likelihood function is defined as the sum of the marginal log-likelihoods, such as 
%\begin{equation}
%\ln p(\mathbf{y}_{1:\mathtt{Tr}}|\bm\theta)  = \displaystyle\sum_{t=1}^{\mathtt{Tr}} \ln p(\mathbf{y}_{t}|\mathbf{y}_{1:t-1},\bm \theta) = \displaystyle\sum_{t=1}^{\mathtt{Tr}} \ln \left[ \sum_{j=1}^{\mathtt{S}} \sum_{i=1}^{\mathtt{S}} \mathcal{L}_{t}^{i(j)} \pi_{t-1|t-1}^{i} Z_{t}^{i(j)} \right] \text{,}
%\label{EQ:LP}
%\end{equation}
%where $\mathcal{L}_{t}^{i(j)}$ and  $\pi_{t-1|t-1}^{i}$ are computed at each time $t$ from the Switching Kalman Filter; $\mathtt{S}$ is the total number of model class, and the values of $Z_{t}^{i(j)}$ are known from the current set of model parameters.
%The maximum log a posteriori procedure consists in identifying the point estimates by maximizing the log A Posteriori PDF, such as
%\begin{equation*}
%\bm\theta^{*} = \underset{\bm\theta}{\text{arg}\max}\left[\ln p(\bm\theta|\mathbf{y}_{1:\mathtt{Tr}}) \right] \text{,}
%\end{equation*}
%where $\bm\theta^{*}$ are the optimized model parameters values.
%
%\subsubsection{Maximum log Likelihood Estimation (MLE)}
%
%The Maximum log Likelihood Estimation (MLE) is a special case of the MAP where the prior PDF $p(\bm\theta)$ is assumed to be uniform \cite{gelman2014bayesian}.
%Therefore, the Maximum log Likelihood procedure consists in identifying the point estimates by maximizing the log likelihood PDF, such as
%\begin{equation*}
%\bm\theta^{*} = \underset{\bm\theta}{\text{arg}\max}\left[\ln  p(\mathbf{y}_{1:\mathtt{Tr}}|\bm\theta) \right] \text{,}
%\end{equation*}
%where $\bm\theta^{*}$ are the optimized model parameters values.
%
%
%\subsubsection{Laplace Approximation}
%
%The MAP and MLE are point estimation methods which do not take into account the uncertainty in the parameter estimates $\bm\theta^{*}$. 
%The estimation of the uncertainties in the model parameters estimates can be addressed using the Laplace approximation \cite{gelman2014bayesian} so that
%$$p(\bm\theta|\mathbf{y}_{1:\mathtt{Tr}})  \approx  \mathcal{N}\left(\bm\theta;\bm\theta^{*},-\mathbf{H}(\bm\theta^{*})^{-1}\right),
%\label{EQ: LaA}
%$$
%where $\mathbf{H}(\bm\theta^{*})$ is the second derivative of the log a posteriori or log likelihood PDF evaluated at the optimal parameter values $\bm\theta^{*}$. 
%
%\subsubsection{Gradient-based optimization}
%
%The gradient-based optimizations techniques are iterative approaches which can be used to find the model parameters that correspond to the maximum of a target PDF, hereafter noted $\mathcal{T}(\bm{\theta})$.
%The function $\mathcal{T}(\bm{\theta})$  is either the log a posteriori or the log likelihood PDF computed from the data.
%One iteration of gradient based algorithm is
%
%\begin{equation}
%{\bm\theta}_{\text{new}}  = {\bm\theta}_{\text{old}} - \eta \nabla \mathcal{T}(\bm{\theta}_{\text{old}}),
%\label{EQ:GBA}
%\end{equation}
%
%where $\eta$ is the learning rate, and $\nabla$ the first derivative.
%
%\paragraph{Parameter-wise Newton-Raphson}
%
%The parameter-wise Newton-Raphson \cite{gelman2014bayesian} algorithm is an iterative approach which can be used to find the model parameters that correspond to the maximum of a target PDF, hereafter noted $\mathcal{T}_{1:\mathtt{Tr}}(\bm{\theta})$.
%The underscripts $1:\mathtt{Tr}$ indicate that the target function is evaluated using a \emph{training dataset} of length $\mathtt{Tr}$.
%%The function $\mathcal{T}_{1:\mathtt{Tr}}(\bm{\theta})$  is either the log a posteriori or the log likelihood PDF.
%The Newton-Raphson algorithm adaptively sets the learning rate using the second derivative and a factor noted $\lambda$.
%One \emph{iteration} of the Newton-Raphson algorithm is
%\begin{equation}
%{\theta}_{\text{new}}^{i}  = {\theta}_{\text{old}}^{i} - \lambda \frac{\nabla \mathcal{T}_{1:\mathtt{Tr}}(\bm{\theta}_{\text{old}}^{i}) }{  \nabla^{2} \mathcal{T}_{1:\mathtt{Tr}}(\bm{\theta}_{\text{old}}^{i})},
%\label{EQ:NR}
%\end{equation}
%where $i$ is the index of the parameter being learned, $\nabla$ the first derivative, $\nabla^{2}$ the second derivative.
%$\bm{\theta}_{\text{old}}$ and $\bm{\theta}_{\text{new}}$ are the previous and updated vector of model parameters. 
%One parameter is updated at each iteration.
%The convergence of each model parameters is reached when the following conditions are satisfied
%\begin{equation}
%\left\{\begin{array}{ccc}
%\mathcal{T}_{1:\mathtt{Tr}}(\bm\theta^{i}_{\text{old}}) &<&\mathcal{T}_{1:\mathtt{Tr}}(\bm\theta^{i}_{\text{new}})\\[4pt]
%\left|\mathcal{T}_{1:\mathtt{Tr}}(\bm\theta^{i}_{\text{new}}) -  \mathcal{T}_{1:\mathtt{Tr}}(\bm\theta^{i}_{\text{old}})\right| &\leq& \tau \cdot \left|\mathcal{T}_{1:\mathtt{Tr}}(\bm\theta^{i}_{\text{old}})\right|
%\end{array}\right.,
%\label{EQ:STC}
%\end{equation}
%where $\tau$ is a termination tolerance.
%The Newton-Raphson algorithm stops when each model parameters has reached the convergence.
%
%\paragraph{Stochastic gradient}
%
%In the stochastic gradient technique, the target function and its derivatives are approximated at each iteration using a \emph{mini-batch} of data of length $\mathtt{Tb} \ll \mathtt{Tr}$.
%Therefore, the target function is noted $\mathcal{T}_{1:\mathtt{Tb}}(\bm{\theta})$.
%At each iteration, the beginning of the mini-batch is selected randomly.
%One \emph{epoch} consists in one pass over the full training dataset (i.e. all the training data have been seen once).
%Therefore, one epoch is made of many iterations.
%Note that more than one model parameters is usually updated during one epoch.
%Several epochs are needed to reach convergence.
%%Classical implementation of stochastic gradient algorithm includes momentum approach (e.g MMT optimizer) or adaptive learning rate (e.g. Adam optimizer) to increase the performance \cite{Goodfellow-et-al-2016}.  
%The convergence is reached when the following condition between two successive epochs is satisfied 
%\begin{equation}
%\mathcal{T}^{\text{epoch}} (\bm\theta) > \tau  \cdot \mathcal{T}^{\text{epoch-1}} (\bm\theta)
%\label{EQ:SGT}
%\end{equation}
%where $0 \le \tau \le 1$ is a termination tolerance.
%Classical implementation of stochastic gradient algorithm includes momentum approach (e.g MMT optimizer) or adaptive learning rate (e.g. Adam optimizer) to increase the performance \cite{Goodfellow-et-al-2016}.  
%
%\paragraph{Approximation of the derivatives}
%
%In many cases, the derivatives of $\mathcal{T}(\bm{\theta})$ cannot be computed analytically.
%Therefore, the derivatives are approximated numerically using the central differentiation scheme, such as
%\begin{gather}
%\begin{aligned}
% \nabla \mathcal{T}(\bm\theta^{i}) & = \frac{\partial \mathcal{T} (\bm\theta) }{\partial \theta^{i}} \approx \frac{\mathcal{T} (\bm\theta + \mathbb{I}(i)\Delta \theta^{i} )  -  \mathcal{T} (\bm\theta - \mathbb{I}(i)\Delta \theta^{i} ) }{2\Delta \theta^{i}}  \\
% \nabla^{2} \mathcal{T}(\bm\theta^{i}) & = \frac{\partial^{2} \mathcal{T} (\bm\theta) }{\partial^{2} \theta^{i}} \approx \frac{\mathcal{T} (\bm\theta + \mathbb{I}(i)\Delta \theta^{i} )  -  2 \mathcal{T} (\bm\theta) +  \mathcal{T} (\bm\theta - \mathbb{I}(i)\Delta \theta^{i} ) }{(\Delta \theta^{i})^{2}},
%\label{EQ:numericaldiff}
%\end{aligned}
%\end{gather}
%where $\Delta \theta^{i}$ is a small perturbation to the value of the $i^{\text{th}}$ model parameters and $\mathbb{I}(i)$ is an indicator vector for which all values are equal to $0$, except the $i^{\text{th}}$ value which is equal to one.
%
%
%\subsubsection{Model parameter space transformation}
%\label{SS:THSpaceTransformation}
%
%There are some model parameters which are defined in a bounded interval.
%For instance, the standard deviation model parameters are real numbers that lie in the $[0, +\infty]$ interval.
%%The autoregression coefficient model parameters are real numbers that lie in the $[0, 1]$ interval.
%Therefore, during the learning procedure, it may happen that new model parameters $\bm\theta_{\text{new}}$ are proposed outside their valid interval.
%Those parameters must be rejected, which strongly hinders the computational efficiency of the learning algorithm.
%The solution employed in OpenBDLM is to transform the bounded space into an unbounded one, where the parameters lie in the interval $[ -\infty, +\infty ]$. The transformation is done using a function $g(.)$ so that, 
%\begin{equation}
%\theta^{\text{tr}} = g(\theta) \text{, }\quad \theta^{\text{tr}} \in [-\infty, +\infty ] \text{.}
%\end{equation}
%The choice of the function $g(.)$ depends on the bound of $\theta$. 
%Three cases generally occur:
%\begin{itemize}
%\item $ \theta \in [-\infty, +\infty ]$ , $g(\theta) = 1$, so that $\theta^{\text{tr}} = \theta$ and $\theta = \theta^{\text{tr}} $
%\item $ \theta \in [0, +\infty ]$, $g(\theta) = \ln(\theta)$, so that $\theta^{\text{tr}} = \ln(\theta) $ and $\theta = e^{\theta^{\text{tr}}} $
%\item $ \theta \in [\text{a}, \text{b}]$, $g(\theta) = \text{sigmoid}(\theta)$, so that $\theta^{\text{tr}} = -\ln \left( \frac{b-a}{\theta-a} - 1\right) $, and $\theta = \left( \frac{b-a}{1+e^{-\theta^{\text{tr}}}} + a \right)$
%\end{itemize}
%For instance, the standard deviation model parameters are real numbers that lie in the $[0, +\infty]$ interval and the logarithm transformation is used.
%Moreover, the autoregression coefficient model parameters are real numbers that lie in the $[0, 1]$ interval, and the sigmoid transformation is used.

\subsection{Block components}
\label{SS:BlockComponent}
The block components are pieces of the full model.
Each block component is used to describe a given dynamics for a given time series.
Therefore, each block component has its own transition and observation model, which are associated with some model parameters.
Each block component can be associated with one or more hidden states variables.
%The types of block components supported in the current OpenBDLM version are listed in the next sections.
The block components are then assembled to build the full model.
The block components associated with irreversible change in the time series belongs to the \emph{baseline} component.
The other block components are associated with reversible change in the time series.
The \emph{compatible} block component are needed to model switching dynamics in the baseline of the time series.

\subsubsection{Local level (baseline)}

The local level block component describes the local mean of a stationary time series (no trend and no acceleration) \cite{STC:STC2035}. 
The local level describes irreversible changes.\\

\noindent
Number of hidden states: 1\\

Hidden states vector: 
\begin{gather*}
\mathbf{x}^{\mathtt{LL}} = [x^{\mathtt{LL}}]
\end{gather*}
Transition matrix: 
\begin{gather*}
\mathbf{A}^{\mathtt{LL}}=[1]
\end{gather*}
Observation matrix: 
\begin{gather*}
\mathbf{C}^{\mathtt{LL}}=[1]
\end{gather*}
Process noise covariance matrix: 
\begin{gather*}
\mathbf{Q}^{\mathtt{LL}}=[(\sigma_{w}^{\mathtt{LL}})^{2}]
\end{gather*}
Model parameters: 
\begin{gather*}
\bm\theta^{\mathtt{LL}}=[\sigma_{w}^{\mathtt{LL}} ]
\end{gather*}

\noindent
$\sigma_{w}^{\mathtt{LL}}$ is the process noise standard deviation which can be learned from the data.

\subsubsection{Local trend (baseline)}

The local trend block component describes the local mean of a trend-stationary time series (trend and no acceleration) \cite{STC:STC2035}. 
The local trend describes irreversible changes.\\

\noindent
Number of hidden states: 2\\

Hidden states vector: 
\begin{gather*}
 \mathbf{x}^{\mathtt{LT}} = [x^{\mathtt{L}}, x^{\mathtt{LT}}]^{\intercal}
 \end{gather*}
Transition matrix: 
\begin{gather*}
\mathbf{A}^{\mathtt{LT}}= \left[\begin{array}{cc}1 &\Delta t\\0&1\end{array}\right]
\end{gather*}
Observation matrix: 
\begin{gather*}
\mathbf{C}^{\mathtt{LT}}=[1, 0]
\end{gather*}
Process noise covariance matrix: 
\begin{gather*}
\mathbf{Q}^{\mathtt{LT}}= (\sigma_{w}^{\mathtt{LT}})^{2}\left[\begin{array}{cc}\tfrac{\Delta t^{4}}{4} &\tfrac{\Delta t^{3}}{2}\\\tfrac{\Delta t^{3}}{2}&\Delta t^{2}\end{array}\right]
\end{gather*}
Model parameters: 
\begin{gather*}
\bm\theta^{\mathtt{LT}}=[\sigma_{w}^{\mathtt{LT}} ]
\end{gather*}

\noindent
$\sigma_{w}^{\mathtt{LT}}$ is the process noise standard deviation, which can be learned from the data, and $\Delta t$ is the local timestep computed from the data.


\subsubsection{Local acceleration (baseline)}

The local acceleration block component describes the local mean of a acceleration-stationary time series \cite{STC:STC2035}. 
It describes irreversible changes.\\

\noindent
Number of hidden states: 3\\

Hidden states vector: 
\begin{gather*}
\mathbf{x}^{\mathtt{LA}} = [x^{\mathtt{L}}, x^{\mathtt{T}} ,  x^{\mathtt{LA}}]^{\intercal}
\end{gather*}
Transition matrix: 
\begin{gather*}
\mathbf{A}^{\mathtt{LA}}=  \left[\begin{array}{ccc}1 &\Delta t&\Delta t^{2}\\0&1&\Delta t\\0&0&1\end{array}\right]
\end{gather*}
Observation matrix: 
\begin{gather*}
\mathbf{C}^{\mathtt{LA}}=[1, 0, 0]
\end{gather*}
Process noise covariance matrix: 
\begin{gather*}
\mathbf{Q}^{\mathtt{LA}}=(\sigma_{w}^{\mathtt{LA}})^{2}\left[\begin{array}{ccc}\tfrac{\Delta t^{4}}{4} &\tfrac{\Delta t^{3}}{2} &\tfrac{\Delta t^{2}}{2}\\\tfrac{\Delta t^{3}}{2} &\Delta t^{2}&\Delta t\\\tfrac{\Delta t^{2}}{2}&\Delta t&1\end{array}\right]
\end{gather*}
Model parameters: 
\begin{gather*}
\bm\theta^{\mathtt{LA}}=[\sigma_{w}^{\mathtt{LA}} ]
\end{gather*}

\noindent
$\sigma_{w}^{\mathtt{LA}}$ is the process noise standard deviation, which can be learned from the data, and $\Delta t$ is the local timestep computed from the data.



\subsubsection{Local level compatible trend (baseline)}

The local level trend compatible component must be used in case of model switching between a local level model and a local trend model \cite{Nguyen2018}.
The local level trend compatible block component describes the local mean of a stationary time series. 
It describes irreversible changes.\\

\noindent
Number of hidden states: 1\\

Hidden states vector: 
\begin{gather*}
 \mathbf{x}^{\mathtt{LcT}} = [x^{\mathtt{LL}}, x^{\mathtt{LTc}}=0]^{\intercal}
 \end{gather*}
Transition matrix: 
\begin{gather*}
\mathbf{A}^{\mathtt{LcT}}= \left[\begin{array}{cc}1 & 0\\0&0\end{array}\right]
\end{gather*}
Observation matrix: 
\begin{gather*}
\mathbf{C}^{\mathtt{LcT}}=[1, 0]
\end{gather*}
Process noise covariance matrix: 
\begin{gather*}
\mathbf{Q}^{\mathtt{LcT}}=(\sigma_{w}^{\mathtt{LcT}})^{2}\left[\begin{array}{cc}1 &0\\0&0\end{array}\right]
\end{gather*}
Model parameters: 
\begin{gather*}
\bm\theta^{\mathtt{LcT}}=[\sigma_{w}^{\mathtt{LcT}} ]
\end{gather*}

\noindent
$\sigma_{w}^{\mathtt{LcT}}$ is the process noise standard deviation, which can be learned from the data, and $\Delta t$ is the local timestep computed from the data.

\subsubsection{Local level compatible acceleration (baseline)}

The local level acceleration compatible component must be used in case of model switching between a local level model and a local acceleration model \cite{Nguyen2018}.
The local level acceleration compatible block component describes the local mean of a stationary time series.
It describes irreversible changes.\\

\noindent
Number of hidden states: 1\\

Hidden states vector:
\begin{gather*}
 \mathbf{x}^{\mathtt{LcA}} = [x^{\mathtt{LL}}, x^{\mathtt{LTc}}=0, x^{\mathtt{LAc}}=0]^{\intercal}
 \end{gather*}
Transition matrix: 
\begin{gather*}
\mathbf{A}^{\mathtt{LcA}}= \left[\begin{array}{ccc}1&0&0\\0&0&0\\0&0&0\end{array}\right]
\end{gather*}
Observation matrix: 
\begin{gather*}
\mathbf{C}^{\mathtt{LcA}}=[1, 0, 0]
\end{gather*}
Process noise covariance matrix: 
\begin{gather*}
\mathbf{Q}^{\mathtt{LcA}}=(\sigma_{w}^{\mathtt{LcA}})^{2}\left[\begin{array}{ccc}1&0&0\\0&0&0\\0&0&0\end{array}\right]
\end{gather*}
Model parameters: 
\begin{gather*}
\bm\theta^{\mathtt{LcA}}=[\sigma_{w}^{\mathtt{LcA}} ]
\end{gather*}

\noindent
$\sigma_{w}^{\mathtt{LcA}}$ is the process noise standard deviation, which can be learned from the data, and $\Delta t$ is the local timestep computed from the data.

\subsubsection{Local trend compatible acceleration (baseline)}
The local trend acceleration compatible component must be used in case of model switching between a local trend model and a local acceleration model \cite{Nguyen2018}.
The local trend acceleration compatible block component describes the local mean of a trend-stationary time series. 
It describes irreversible changes.\\

\noindent
Number of hidden states: 2\\
Hidden states vector: 
\begin{gather*}
 \mathbf{x}^{\mathtt{TcA}} = [x^{\mathtt{L}}, x^{\mathtt{LT}} , x^{\mathtt{LAc}}=0]^{\intercal}
 \end{gather*}
Transition matrix: 
\begin{gather*}
\mathbf{A}^{\mathtt{TcA}}= \left[\begin{array}{ccc}1&\Delta t&0\\0&1&0\\0&0&0\end{array}\right]
\end{gather*}
Observation matrix: 
\begin{gather*}
\mathbf{C}^{\mathtt{TcA}}=[1, 0, 0]
\end{gather*}
Process noise covariance matrix: 
\begin{gather*}
\mathbf{Q}^{\mathtt{TcA}}=(\sigma_{w}^{\mathtt{TcA}})^{2}  \left[\begin{array}{ccc}\tfrac{\Delta t^{4}}{4} &\tfrac{\Delta t^{3}}{2}&0\\\tfrac{\Delta t^{3}}{2}&\Delta t^{2}&0\\0&0&0\end{array}\right] 
\end{gather*}
Model parameters: 
\begin{gather*}
\bm\theta^{\mathtt{TcA}}=[\sigma_{w}^{\mathtt{TcA}} ]
\end{gather*}

\noindent
$\sigma_{w}^{\mathtt{TcA}}$ is the process noise standard deviation, which can be learned from the data, and $\Delta t$ is the local timestep computed from the data.



\subsubsection{Periodic (Fourier form)}

The periodic (Fourier form) block component describes a periodic pattern in the time series using Fourier form \cite{west1999bayesian,STC:STC2035}. 
The periodic Fourier form allows modelling sine-like periodic pattern in time series.
It describes reversible changes.\\

\noindent
Number of hidden states: 2\\

Hidden states vector: 
\begin{gather*}
\mathbf{x}^{\mathtt{P}} = [x^{\mathtt{P}_ {1}}, x^{\mathtt{P}_{2}}]^{\intercal}
\end{gather*}
Transition matrix: 
\begin{gather*}
\mathbf{A}^{\mathtt{P}}= \left[\begin{array}{cc}\cos \omega &\sin \omega\\-\sin \omega&\cos \omega\end{array}\right]
\end{gather*}
Observation matrix: 
\begin{gather*}
\mathbf{C}^{\mathtt{P}}=[1, 0]
\end{gather*}
Process noise covariance matrix:
\begin{gather*}
\mathbf{Q}^{\mathtt{P}}=(\sigma_{w}^{\mathtt{P}})^{2}\left[\begin{array}{cc}1 &0\\0&1\end{array}\right]
\end{gather*}
Model parameters: 
\begin{gather*}
\bm\theta^{\mathtt{P}}=[\sigma_{w}^{\mathtt{P}}, p^{\mathtt{P}} ]
\end{gather*}

\noindent
$\sigma_{w}^{\mathtt{P}}$ is the process noise standard deviation and $p$ the period in days, which can be learned from the data, and $\Delta t$ is the local timestep computed from the data.
 $\omega=\frac{2\pi \Delta t}{p}$ is the angular of frequency defined from the period $p$, given in days.


\subsubsection{Periodic (Kernel regression form)}\label{SSS:KR}

The periodic (Kernel regression form) block component describes a periodic pattern in the time series using periodic kernel regression  \cite{Nguyen2019KRBDLM}. 
The periodic Kernel regression form allows modelling form-free periodic pattern in time series.
It describes reversible changes.
The periodic kernel measures the similarity between pairs of covariates, and it is defined as
\begin{gather*}
k(t_{i},t_{j})=\exp\left[-\frac{2}{\ell^2}\sin\left( \pi\frac{t_i-t_{j}}{p}\right)^{2}\right].
\end{gather*}
The kernel output $k(t_{i},t_{j})\in(0,1)$ measures the similarity between two timestamps $t_{i}$ and $t_{j}$ as a function of the distance between these, as well as a function of two parameters; the period and kernel length, $\bm{\theta}=[p,\ell]$.
\noindent\\
Number of hidden states:  $\mathtt{L}^{\mathtt{KR}}+1$\\

Hidden states vector: 
\begin{gather*}
\mathbf{x}^{\mathtt{KR}} = [x^{\mathtt{KR}}_{0}, x^{\mathtt{KR}}_{1}, \dots, x^{\mathtt{KR}}_{\mathtt{L}^{\mathtt{KR}}}]^{\intercal}
\end{gather*}
Transition matrix: 
\begin{gather*}
\mathbf{A}^{\mathtt{KR}}= \left[\begin{array}{cc}0 &\tilde{\bm k}^{\mathtt{KR}}(t, \mathbf{t}^{\mathtt{KR}})\\\mathbf{0}&\mathbf{I}_{\mathtt{L}^{\mathtt{KR}}}\end{array}\right]
\end{gather*}
Process noise covariance matrix:
\begin{gather*}
\mathbf{Q}^{\mathtt{KR}}=\left[\begin{array}{cc}(\sigma_{w,0}^{\mathtt{KR}})^{2} &\mathbf{0}\\\mathbf{0}&(\sigma_{w,1}^{\mathtt{KR}})^{2}\cdot\mathbf{I}_{\mathtt{L}^{\mathtt{KR}} }\end{array}\right]
\end{gather*}
Observation matrix: 
\begin{gather*}
\mathbf{C}^{\mathtt{KR}}=[1, 0, \dots, 0]
\end{gather*}
Model parameters: 
\begin{gather*}
\bm\theta^{\mathtt{KR}}=[ p^{\mathtt{KR}},\ell^{\mathtt{KR}},  \sigma_{w,0}^{\mathtt{KR}}, \sigma_{w,1}^{\mathtt{KR}}]
\end{gather*}

\noindent
In the transition matrix, $\tilde{\bm k}^{\mathtt{KR}}(t,\mathbf{t}^{\mathtt{KR}})$ corresponds to the normalized kernel, $k(t,\mathbf{t}^{\mathtt{KR}})/\sum_{t} k(t,\mathbf{t}^{\mathtt{KR}})$. $\tilde{\bm k}^{\mathtt{KR}}(t,\mathbf{t}^{\mathtt{KR}})$ is parameterized by the kernel width $\ell^{\mathtt{KR}}$, its period $p^{\mathtt{KR}}$, and a vector of $\mathtt{L}^{\mathtt{KR}}$ timestamps $\mathbf{t}^{\mathtt{KR}}=[t_{1}^{\mathtt{KR}},\cdots,t_{\mathtt{L}^{\mathtt{KR}}}^{\mathtt{KR}}]$ where each timestamp $t_{i}^{\mathtt{KR}}$ is associated with a hidden control point value $x_{i}^{\mathtt{KR}}$. 
$\sigma_{w,1}^{\mathtt{KR}}$ controls the process noise  variance of the hidden control points between successive time steps and $\sigma_{w,0}^{\mathtt{KR}}$ controls the time-independent process noise in the hidden predicted pattern.
$p^{\mathtt{KR}}$ and $\ell^{\mathtt{KR}}$ give the period and correlation length of the kernel.


\subsubsection{First order autoregressive}

The first order autoregressive component describes the time-dependent model errors (i.e the residual between the model prediction and the data) \cite{STC:STC2035}. 
It describes reversible changes.\\

\noindent
Number of hidden states: 1\\

Hidden states vector: 
\begin{gather*}
\mathbf{x}^{\mathtt{AR}} = [x^{\mathtt{AR}}]
\end{gather*}
Transition matrix: 
\begin{gather*}
\mathbf{A}^{\mathtt{AR}}=  [\phi^{\mathtt{AR}}]
\end{gather*}
Observation matrix: 
\begin{gather*}
\mathbf{C}^{\mathtt{AR}}=[1]
\end{gather*}
Process noise covariance matrix: 
\begin{gather*}
\mathbf{Q}^{\mathtt{AR}}=[(\sigma_{w}^{\mathtt{AR}})]
\end{gather*}
Model parameters: 
\begin{gather*}
\bm\theta^{\mathtt{AR}}=[\sigma_{w}^{\mathtt{AR}}, \phi^{\mathtt{AR}} ]
\end{gather*}

\noindent
$\sigma_{w}^{\mathtt{AR}}$ is the process noise standard deviation, and $\phi^{\mathtt{AR}}$ the autoregressive coefficient.

\subsubsection{Local Intervention}\label{SSS:LI}

The local intervention block component describes the discrete shifts occurring in a time series. Shifts typically happens a sensor fails; when a sensor fails, the data start to be missing (i.e. \lstinline[basicstyle = \mlttfamily \small, backgroundcolor = \color{light-gray}]!NaN!) and it often takes from several weeks to several months before the sensor is replaced. When the sensor is replaced, it is in most cases re-initialized at a different initial value than the previous sensor which lead to a discrete shift in the time series, as depicted in Figure~\ref{fig:DataSummary1}. When using a Level intervention component, the user must provide discrete timestamps where it is required to estimate the magnitude of a discrete shift in the dataset. A user can do so by specifying in the configuration file \lstinline[basicstyle = \mlttfamily \small, backgroundcolor = \color{light-gray}]!data.interventions=[t_{1}, t_{2}, ... , t_{n}]!, where \lstinline[basicstyle = \mlttfamily \small, backgroundcolor = \color{light-gray}]!n! is the number of interventions. 

The local intervention describes irreversible changes.\\

\noindent
Number of hidden states: 1\\

Hidden states vector: 
\begin{gather*}
\mathbf{x}^{\mathtt{LI}} = [x^{\mathtt{LI}}]
\end{gather*}
Transition matrix: 
\begin{gather*}
\mathbf{A}^{\mathtt{LI}}=[1]
\end{gather*}
Observation matrix: 
\begin{gather*}
\mathbf{C}^{\mathtt{LI}}=[1]
\end{gather*}
Process noise covariance matrix: 
\begin{gather*}
\mathbf{Q}^{\mathtt{LI}}=[(\sigma_{w}^{\mathtt{LI}})^{2}]
\end{gather*}
Model parameters: 
\begin{gather*}
\bm\theta^{\mathtt{LI}}=[\mu_{b}^{\mathtt{LI}}, \sigma_{b}^{\mathtt{LI}} ]
\end{gather*}
\noindent
$\sigma_{w}^{\mathtt{LI}}$ is the standard deviation describing the uncertainty associated with the magnitude of the shift and $\mu_{b}^{\mathtt{LI}}$ is its expected magnitude;  Both parameters can be kept to their default values or be learned from the data.

For the Local intervention component, the Equation \ref{EQ:SSM_Transition} is modified to include an additional  intervention term $b_{t}$
\begin{equation}
  \mathbf{x}_{t}^{\mathtt{LI}}=\mathbf{A}_{t}^{\mathtt{LI}}\mathbf{x}_{t-1}^{\mathtt{LI}}+{w}_{t}^{\mathtt{LI}}+b_{t}^{\mathtt{LI}},\quad\left\{
  \begin{array}{l}
{w}_{t}^{\mathtt{LI}}\sim \mathcal{N}({0},
\mathbf{Q}_{t}^{\mathtt{LI}})\\[4pt]
b_{t}^{\mathtt{LI}}\sim\mathcal{N}(\mu_{b}^{\mathtt{LI}},
\sigma_{b}^{\mathtt{LI}})
\end{array}\right.
\end{equation}
The local Intervention component allows estimating the shifts $\mathbf{x}_{t|t}^{\mathtt{LI}}$ caused by the interventions for which the discrete timestamps are specified in \lstinline[basicstyle = \mlttfamily \small, backgroundcolor = \color{light-gray}]!data.interventions!. 



\subsection{Handling non-uniform time vector and missing data}
\label{SS:HandlingNonUniformMissingData}

\subsubsection{Non-uniform time vector}
\label{SS:NonUniform}

Non uniform time vector occurs when the time between two successive data measurements (i.e. the timestep) varies with time.
In order to accommodate non-uniform time vector, OpenBDLM employs an approximate method which is based on a reference time step $\Delta t^{\text{ref}} $ \cite{STC:STC2035}. 
The reference time-step is a value corresponding to the most frequent time step in the time series.
All parameter values in the parameter set $\bm \theta$ are estimated for the reference time step. 
Therefore, for local time step $\Delta t$ different than the reference timestep $\Delta t^{\text{ref}} $, the parameters value must be adapted accordingly.
As an approximation, the model error standard deviations  $\sigma_{w}$ in $\mathbf{Q}_{t}$ are scaled proportionally to the ratio between the current time step and the reference time step so that,
\begin{gather*}
\sigma_{w}^{\Delta t}= \sigma_{w}^{\Delta t ^{\text{ref}}}\frac{\Delta t}{\Delta t ^{\text{ref}}}.
\end{gather*}
Therefore, the amount of process noise in the prediction model increases as the local time step increase with respect to the reference time step.

The transition matrix $\mathbf{A}^{\mathtt{AR}}$ contains the autoregressive coefficients $\phi^{\mathtt{AR}}$ that are recursively multiplied with the hidden state at each time step. 
To account for time step changes, the autoregressive coefficients are elevated to the power of the ratio between the current time step and the reference time step, such as
\begin{gather*}
\phi^{\mathtt{AR}, \Delta t}=  (\phi^{\mathtt{AR}, \Delta t ^{\text{ref}}})^{\frac{\Delta t}{\Delta t ^{\text{ref}}}}.
\end{gather*}
Therefore, the autocorrelation between successive data samples in the autoregressive prediction model decreases as the local time step increase with respect to the reference time step.
Note that this procedure is an approximation.
\subsubsection{Missing data (NaN)}

The presence of missing data (\lstinline[basicstyle = \mlttfamily \small ]!NaN!) for specific timestamps prevents the completion of the Kalman update-step \cite{STC:STC2035}.
However, the prediction step using the current transition model can be done.
%No update is performed at times associated with missing data (NaN), and only the prediction step is performed.
Therefore, BDLM automatically fills gaps when data are missing using the transition model in the prediction step.


\subsection{Dependencies between time series}
\label{S:Dependencies}
The dependencies between time series are handled by adding regression coefficients $\phi^{i|j}$ in the observation matrix (See \S\ref{S:ExampleDispTemp}).
For a dataset with $\mathtt{D}$ time series, the observation matrix is
\begin{equation*}
\mathbf{C}=\left[\begin{array}{cccccc}
\mathbf{C}^{1}& \mathbf{C}_{1,2}^{c}&\cdots & \mathbf{C}_{1,j}^{c}&\cdots& \mathbf{C}_{1,\mathtt{D}}^{c}\\
\mathbf{C}_{2,1}^{c}& \mathbf{C}^{2}&\cdots& \mathbf{C}_{2,j}^{c}&\cdots& \mathbf{C}_{2,\mathtt{D}}^{c}\\
\vdots&\vdots& \vdots& \vdots& \ddots& \vdots\\
\mathbf{C}_{i,1}^{c}& \mathbf{C}_{i,2}^{c}&\cdots&\mathbf{C}_{i,j}^{c}&\cdots&\mathbf{C}_{i,\mathtt{D}}^{c}\\
\vdots&\vdots& \vdots& \vdots& \ddots& \vdots\\
\mathbf{C}_{\mathtt{D},1}^{c}& \mathbf{C}_{\mathtt{D},2}^{c}&\cdots& \mathbf{C}_{\mathtt{D},j}^{c}&\cdots& \mathbf{C}^{\mathtt{D}}
\end{array}\right] \text{.}
\end{equation*}
The dependence matrix is a matrix with $0$ and $1$ which is used to indicate which time series have dependencies between each others, such as 

\begin{equation*}
\mathbf{D}=\left[\begin{array}{cccccc}
1&d_{1,2}&\cdots&d_{1,j}&\cdots&d_{1,\mathtt{D}}\\
d_{2,1}&1&\cdots&d_{2,j}&\cdots&d_{2,\mathtt{D}}\\
\vdots&\vdots&\vdots&\vdots&\ddots&\vdots\\
d_{i,1}&d_{i,2}&\cdots&1&\cdots&d_{i,\mathtt{D}}\\
\vdots&\vdots&\vdots&\vdots&\ddots&\vdots\\
d_{\mathtt{D},1}&d_{\mathtt{D},2}&\cdots&d_{\mathtt{D},j}&\cdots&1\\
\end{array}\right] \text{.}
\end{equation*}
Then, 
\begin{itemize}
\item if $d_{i,j}=0$, $\mathbf{C}_{i,j}^{c}=[\mathbf{0}]$
\item if $d_{i,j}=1$, $\mathbf{C}_{i,j}^{c}=\left[\phi^{i|j}_{1},\phi^{i|j}_{2},\cdots,\phi^{i|j}_{k_{j}}\right]$ where $k_{j}$ is the number of hidden states associated with the $j^{th}$ time series.
\end{itemize}
The regression coefficient $\phi^{i|j}_{k}$ gives the linear dependence between the $k^{th}$ hidden states of the $j^{th}$ time series and the $i^{th}$ time series.
In OpenBDLM, a dependence model between time series assigns regression coefficient for the observed hidden states associated with block component describing reversible behavior (periodic and autoregressive patterns).
